{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9428891,"sourceType":"datasetVersion","datasetId":5667159}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# <div style=\"text-align:center; border-radius:15px; padding:15px; margin:0; font-size:180%; font-family:Arial, sans-serif; background-color:#C33B2F; color:#EDEBEC; overflow:hidden; box-shadow:0 4px 8px rgba(0, 0, 0, 0.3);\"><b> Retail Sales Predictions </b></div>","metadata":{}},{"cell_type":"markdown","source":"![customers](https://r2.starryai.com/results/1050152342/da955f92-19ae-4e99-ba3e-03e1825c8518.webp)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# <div style=\"text-align:center; border-radius:15px; padding:15px; margin:0; font-size:110%; font-family:Arial, sans-serif; background-color:#196094; color:#EDEBEC; overflow:hidden; box-shadow:0 4px 8px rgba(0, 0, 0, 0.3);\"><b> 1. Introduction </b></div>","metadata":{}},{"cell_type":"markdown","source":"## 📊 About the project\n\nIn retail, being able to predict sales accurately is essential for making smart business decisions. This project focuses on building models to forecast sales by using a dataset that includes various factors affecting sales, such as discounts, marketing spend, and seasonal trends like holidays.\n\nThis project will not only predict sales but also evaluate the performance of different models such as linear regression, decision trees, and gradient boosting methods, among others. The comparison will help identify the most effective model for improving sales forecasting accuracy in real-world retail settings.\n\n## 🔑 Key Objectives:\n- Build and compare different models to predict retail sales.\n- Analyze how features like marketing, discounts, and holidays affect sales.\n- Find the most effective model for forecasting future sales.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# <div style=\"text-align:center; border-radius:15px; padding:15px; margin:0; font-size:110%; font-family:Arial, sans-serif; background-color:#196094; color:#EDEBEC; overflow:hidden; box-shadow:0 4px 8px rgba(0, 0, 0, 0.3);\"><b> 2. Importing Necessary Libraries </b></div>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\n\nfrom scipy import stats\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.linear_model import LinearRegression, SGDRegressor, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom xgboost import XGBRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.losses import MeanSquaredError\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\ncustom_palette = ['#1560B0', '#C33B2F', '#EAD59F', '#6AA8CD', '#D69642', '#D6E5EE', '#695D5E']\nsns.set_theme(context='notebook', palette=custom_palette, style='whitegrid')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-20T12:26:49.006404Z","iopub.execute_input":"2024-09-20T12:26:49.006894Z","iopub.status.idle":"2024-09-20T12:27:06.625741Z","shell.execute_reply.started":"2024-09-20T12:26:49.006836Z","shell.execute_reply":"2024-09-20T12:27:06.624105Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# <div style=\"text-align:center; border-radius:15px; padding:15px; margin:0; font-size:110%; font-family:Arial, sans-serif; background-color:#196094; color:#EDEBEC; overflow:hidden; box-shadow:0 4px 8px rgba(0, 0, 0, 0.3);\"><b> 3. Loading and Understanding Data </b></div>","metadata":{}},{"cell_type":"code","source":"file_path = '/kaggle/input/retail-sales-data-with-seasonal-trends-and-marketing/Retail_sales.csv'\ndf = pd.read_csv(file_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:06.628880Z","iopub.execute_input":"2024-09-20T12:27:06.630012Z","iopub.status.idle":"2024-09-20T12:27:08.474548Z","shell.execute_reply.started":"2024-09-20T12:27:06.629921Z","shell.execute_reply":"2024-09-20T12:27:08.470044Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/retail-sales-data-with-seasonal-trends-and-marketing/Retail_sales.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/retail-sales-data-with-seasonal-trends-and-marketing/Retail_sales.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/retail-sales-data-with-seasonal-trends-and-marketing/Retail_sales.csv'","output_type":"error"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.476652Z","iopub.status.idle":"2024-09-20T12:27:08.477235Z","shell.execute_reply.started":"2024-09-20T12:27:08.476925Z","shell.execute_reply":"2024-09-20T12:27:08.476978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.479160Z","iopub.status.idle":"2024-09-20T12:27:08.479731Z","shell.execute_reply.started":"2024-09-20T12:27:08.479478Z","shell.execute_reply":"2024-09-20T12:27:08.479503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.481699Z","iopub.status.idle":"2024-09-20T12:27:08.482209Z","shell.execute_reply.started":"2024-09-20T12:27:08.481963Z","shell.execute_reply":"2024-09-20T12:27:08.481999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.484407Z","iopub.status.idle":"2024-09-20T12:27:08.485144Z","shell.execute_reply.started":"2024-09-20T12:27:08.484787Z","shell.execute_reply":"2024-09-20T12:27:08.484821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing values\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.487583Z","iopub.status.idle":"2024-09-20T12:27:08.488281Z","shell.execute_reply.started":"2024-09-20T12:27:08.487917Z","shell.execute_reply":"2024-09-20T12:27:08.487967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Store ID'].nunique()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.490960Z","iopub.status.idle":"2024-09-20T12:27:08.491516Z","shell.execute_reply.started":"2024-09-20T12:27:08.491270Z","shell.execute_reply":"2024-09-20T12:27:08.491295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Store Location'].nunique()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.493495Z","iopub.status.idle":"2024-09-20T12:27:08.493979Z","shell.execute_reply.started":"2024-09-20T12:27:08.493726Z","shell.execute_reply":"2024-09-20T12:27:08.493747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Product ID'].nunique()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.495851Z","iopub.status.idle":"2024-09-20T12:27:08.496338Z","shell.execute_reply.started":"2024-09-20T12:27:08.496116Z","shell.execute_reply":"2024-09-20T12:27:08.496139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Product Category'].nunique()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.498024Z","iopub.status.idle":"2024-09-20T12:27:08.498500Z","shell.execute_reply.started":"2024-09-20T12:27:08.498267Z","shell.execute_reply":"2024-09-20T12:27:08.498290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"padding: 20px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border: 2px solid #498394; width: 75%; margin: 0 auto;\">\n    <p style=\"font-size: 20px; font-family: 'Arial'; line-height: 1.5em;\">\n    Initial data exploration reveals the following key points:\n    <ul>\n        <li>🧮 <strong>Observations:</strong> The dataset consists of 30,000 rows and 11 columns.</li>\n        <li>⚠️ <strong>Missing Values:</strong> No missing values are present in the dataset.</li>\n        <li>📊 <strong>Column Types:</strong> The dataset includes a mix of integers, floats, objects, and boolean values.</li>\n        <li>📉 <strong>Marketing and Discounts:</strong> Most days had no marketing spend or discounts applied.</li>\n        <li>💰 <strong>Maximum Values:</strong> The highest marketing spend was $199, and the largest discount offered was 20%.</li>\n        <li>🏪 <strong>Store ID:</strong> There is only one unique value in 'Store ID', so this column can be dropped.</li>\n        <li>🔢 <strong>Product ID:</strong> While 'Product ID' is numerical, it contains 42 unique values.</li>\n        <li>🌍 <strong>Product Location:</strong> There are 243 unique product locations in the dataset.</li>\n    </ul>\n    </p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# <div style=\"text-align:center; border-radius:15px; padding:15px; margin:0; font-size:110%; font-family:Arial, sans-serif; background-color:#196094; color:#EDEBEC; overflow:hidden; box-shadow:0 4px 8px rgba(0, 0, 0, 0.3);\"><b> 4. Exploratory Data Analysis </b></div>","metadata":{}},{"cell_type":"markdown","source":"## ✨ Pairplot","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.500307Z","iopub.status.idle":"2024-09-20T12:27:08.500808Z","shell.execute_reply.started":"2024-09-20T12:27:08.500597Z","shell.execute_reply":"2024-09-20T12:27:08.500619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 📉 Histograms","metadata":{}},{"cell_type":"code","source":"numerical_cols_to_plot = ['Units Sold', 'Sales Revenue (USD)','Marketing Spend (USD)']\n\n# Plot histograms for each numerical column\nfor column in numerical_cols_to_plot:\n   \n    plt.figure(figsize=(8, 5))\n    sns.histplot(data=df, x=column, kde=True, bins=20)\n    plt.title(f'Histogram of {column}')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.502428Z","iopub.status.idle":"2024-09-20T12:27:08.502860Z","shell.execute_reply.started":"2024-09-20T12:27:08.502646Z","shell.execute_reply":"2024-09-20T12:27:08.502668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 📊 Countplots","metadata":{}},{"cell_type":"code","source":"categorical_columns_to_plot = ['Product Category', 'Discount Percentage', 'Day of the Week']\n\n# Plot countplots for each categorical column\nfor column in categorical_columns_to_plot:\n   \n    plt.figure(figsize=(8, 5))\n    sns.countplot(data=df, x=column)\n    plt.title(f'Countplot of {column}')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.505313Z","iopub.status.idle":"2024-09-20T12:27:08.505878Z","shell.execute_reply.started":"2024-09-20T12:27:08.505635Z","shell.execute_reply":"2024-09-20T12:27:08.505660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🥧 Pie Chart","metadata":{}},{"cell_type":"code","source":"# Define the Holiday Effect categories and count occurences\ncategories = [False, True]\ncounts = df['Holiday Effect'].value_counts().tolist()\n\n# Plot the pie chart with the counts of each Holiday Effect category\nplt.figure(figsize=(6, 6))\nplt.pie(counts, labels=categories, autopct='%1.1f%%', startangle=180, colors=custom_palette)\nplt.title('Holiday Effect Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.507690Z","iopub.status.idle":"2024-09-20T12:27:08.508230Z","shell.execute_reply.started":"2024-09-20T12:27:08.507967Z","shell.execute_reply":"2024-09-20T12:27:08.507996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 📦 Box plots","metadata":{}},{"cell_type":"code","source":"columns_to_plot = ['Product Category', 'Discount Percentage', 'Day of the Week', 'Holiday Effect']\n\n# Plot box plots\nfor column in columns_to_plot:\n   \n    plt.figure(figsize=(8, 5))\n    sns.boxplot(data=df, x=column, y='Sales Revenue (USD)')\n    plt.title(f'Sales Revenue by {column}')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.509624Z","iopub.status.idle":"2024-09-20T12:27:08.510091Z","shell.execute_reply.started":"2024-09-20T12:27:08.509842Z","shell.execute_reply":"2024-09-20T12:27:08.509862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🌡️ Correlation Heatmap","metadata":{}},{"cell_type":"code","source":"# Define the custom colormap\ncolors = [\"#DC462F\", \"#DCE7EE\", \"#1560B0\"]\ncmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors)\n\n# Create a correlation heatmap\nnumeric_df = df.select_dtypes(include=[np.number])\nplt.figure(figsize=(10, 6))\nsns.heatmap(numeric_df.corr(), annot=True, cmap=cmap, center=0, vmin=-1, fmt='.2f')\nplt.title('Correlation Heatmap')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.511653Z","iopub.status.idle":"2024-09-20T12:27:08.512132Z","shell.execute_reply.started":"2024-09-20T12:27:08.511881Z","shell.execute_reply":"2024-09-20T12:27:08.511902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"padding: 20px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border: 2px solid #498394; width: 75%; margin: 0 auto;\">\n    <p style=\"font-size: 20px; font-family: 'Arial'; line-height: 1.5em;\">\n    Observations from the visualization:\n    <ul>\n        <li>📊 <strong>Numerical Distribution:</strong> Numerical columns have a right-skewed distribution.</li>\n        <li>📅 <strong>Days of the Week:</strong> The distribution of days of the week is well balanced.</li>\n        <li>📉 <strong>Discount Percentage:</strong> The distribution of discount percentage is imbalanced, with most values being 0.</li>\n        <li>🛋️📦🍎👗 <strong>Product Categories:</strong> There are 4 product categories: Furniture, Electronics, Groceries, and Clothing.</li>\n        <li>💸 <strong>Revenue by Product Categories:</strong> Electronics and Clothing are correlated with higher revenues.</li>\n        <li>🎉 <strong>Holiday Effect:</strong> The holiday effect is mostly 'False' in 99.5% of the cases (which is expected, as holidays are not daily occurrences).</li>\n        <li>🎁 <strong>Holiday Revenue:</strong> Holidays tend to bring more revenue overall.</li>\n        <li>🔗 <strong>Correlation:</strong> The only highly correlated numerical variables are 'Units Sold' and 'Sales Revenue'.</li>\n    </ul>\n    </p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# <div style=\"text-align:center; border-radius:15px; padding:15px; margin:0; font-size:110%; font-family:Arial, sans-serif; background-color:#196094; color:#EDEBEC; overflow:hidden; box-shadow:0 4px 8px rgba(0, 0, 0, 0.3);\"><b> 5. Machine Learning </b></div>","metadata":{}},{"cell_type":"markdown","source":"## 📏 Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Define features and target variable\nX = df[['Product ID','Store Location', 'Product Category', 'Units Sold', 'Day of the Week',\n        'Discount Percentage', 'Marketing Spend (USD)', 'Holiday Effect']]\ny = df['Sales Revenue (USD)']","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.513388Z","iopub.status.idle":"2024-09-20T12:27:08.513835Z","shell.execute_reply.started":"2024-09-20T12:27:08.513619Z","shell.execute_reply":"2024-09-20T12:27:08.513642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.515827Z","iopub.status.idle":"2024-09-20T12:27:08.516277Z","shell.execute_reply.started":"2024-09-20T12:27:08.516063Z","shell.execute_reply":"2024-09-20T12:27:08.516085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_cols = ['Product ID', 'Store Location', 'Product Category', 'Day of the Week']\nnumerical_cols = ['Units Sold', 'Discount Percentage', 'Marketing Spend (USD)'] \nboolean_cols = ['Holiday Effect']","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.517703Z","iopub.status.idle":"2024-09-20T12:27:08.518182Z","shell.execute_reply.started":"2024-09-20T12:27:08.517910Z","shell.execute_reply":"2024-09-20T12:27:08.517930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define your preprocessing step\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', MinMaxScaler(), numerical_cols),\n        ('bool', 'passthrough', boolean_cols),\n        ('cat', OneHotEncoder(), categorical_cols)\n    ])","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.520417Z","iopub.status.idle":"2024-09-20T12:27:08.520852Z","shell.execute_reply.started":"2024-09-20T12:27:08.520631Z","shell.execute_reply":"2024-09-20T12:27:08.520652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🤖 Training and Comparing 10 Different Models","metadata":{}},{"cell_type":"code","source":"# Initialize list to collect results\nresults = []\n\n# Function to evaluate models and store results for visualization\ndef evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n    pipeline = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', model)\n    ])\n    \n    pipeline.fit(X_train, y_train)\n    \n    # Make predictions on the test set\n    y_pred_test = pipeline.predict(X_test)\n    \n    # Calculate metrics: R² and RMSE\n    test_r2 = r2_score(y_test, y_pred_test)\n    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n    \n    # Print results\n    print(f\"{model_name} Model:\")\n    print(f\"Test R²: {test_r2:.4f}\")\n    print(f\"Test RMSE: {test_rmse:.4f}\\n\")\n    \n    # Append results to the list for visualization\n    results.append({'Model': model_name, 'R²': test_r2, 'RMSE': test_rmse})","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.522701Z","iopub.status.idle":"2024-09-20T12:27:08.523180Z","shell.execute_reply.started":"2024-09-20T12:27:08.522926Z","shell.execute_reply":"2024-09-20T12:27:08.522975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define models to evaluate\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'SGD Regressor': SGDRegressor(),\n    'Random Forest': RandomForestRegressor(),\n    'ElasticNet': ElasticNet(),\n    'K-Neighbors Regressor': KNeighborsRegressor(),\n    'Decision Tree': DecisionTreeRegressor(),\n    'SVR': SVR(),\n    'XGBoost': XGBRegressor(),\n    'Gradient Boosting': GradientBoostingRegressor(),\n    'Bagging': BaggingRegressor()\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.525708Z","iopub.status.idle":"2024-09-20T12:27:08.526193Z","shell.execute_reply.started":"2024-09-20T12:27:08.525927Z","shell.execute_reply":"2024-09-20T12:27:08.525982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterate over the models to evaluate each\nfor model_name, model in models.items():\n    evaluate_model(model, X_train, y_train, X_test, y_test, model_name)\n\n# Convert results to a DataFrame\nresults_df = pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.528388Z","iopub.status.idle":"2024-09-20T12:27:08.529137Z","shell.execute_reply.started":"2024-09-20T12:27:08.528767Z","shell.execute_reply":"2024-09-20T12:27:08.528803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot R² comparison\nplt.figure(figsize=(10, 6))\nsns.barplot(x='R²', y='Model', data=results_df, palette=custom_palette)\nplt.title('Model Comparison (R² Score)')\nplt.show()\n\n# Plot RMSE comparison\nplt.figure(figsize=(10, 6))\nsns.barplot(x='RMSE', y='Model', data=results_df, palette=custom_palette)\nplt.title('Model Comparison (RMSE)')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.531471Z","iopub.status.idle":"2024-09-20T12:27:08.532175Z","shell.execute_reply.started":"2024-09-20T12:27:08.531812Z","shell.execute_reply":"2024-09-20T12:27:08.531847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🎯 Perfect Score, but is it a correct one?","metadata":{}},{"cell_type":"markdown","source":"<div style=\"padding: 20px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); border: 3px solid #C33B2F; border-radius: 10px; width: 75%; margin: 20px auto; background-color: #f9f9f9;\">\n    <p style=\"font-size: 20px; font-family: Arial, sans-serif; line-height: 1.6em; color: #333; text-align: justify;\">\n        We achieved <strong>outstanding results</strong>, with an <strong>R² score of 99.8%</strong>! It's also worth noting that a simple and highly interpretable model, the <strong>Decision Tree</strong>, performed exceptionally well, achieving 99.6%.\n    </p>\n    <p style=\"font-size: 20px; font-family: Arial, sans-serif; line-height: 1.6em; color: #333; text-align: justify;\">\n        While we should be pleased with these results, there's an important issue. I didn't mention it earlier, but by including the <strong>\"Items Sold\"</strong> feature when predicting <strong>\"Sales Revenue\"</strong>, we've introduced <strong>data leakage</strong>. These two features are directly correlated, and in a real-world scenario, we wouldn’t know the number of items sold in advance when predicting future sales. \n        Let's remove this feature and repeat the process.\n    </p>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"## 🔄 Let's Try Again","metadata":{}},{"cell_type":"code","source":"# Define correct features\nX = df[['Product ID','Store Location', 'Product Category', 'Day of the Week','Discount Percentage', 'Marketing Spend (USD)', 'Holiday Effect']]\n\n# Replace numerical columns list without Items Sold\nnumerical_cols = ['Discount Percentage', 'Marketing Spend (USD)'] \n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define your preprocessing step\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', MinMaxScaler(), numerical_cols),\n        ('bool', 'passthrough', boolean_cols),\n        ('cat', OneHotEncoder(), categorical_cols)\n    ])\n\n# Initialize list to collect results\nresults = []\n\n# Function to evaluate models and store results for visualization\ndef evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n    pipeline = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', model)\n    ])\n    \n    pipeline.fit(X_train, y_train)\n    \n    # Make predictions on the test set\n    y_pred_test = pipeline.predict(X_test)\n    \n    # Calculate metrics: R² and RMSE\n    test_r2 = r2_score(y_test, y_pred_test)\n    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n\n    # Print results\n    print(f\"{model_name} Model:\")\n    print(f\"Test R²: {test_r2:.4f}\")\n    print(f\"Test RMSE: {test_rmse:.4f}\\n\")\n    \n    # Append results to the list for visualization\n    results.append({'Model': model_name, 'R²': test_r2, 'RMSE': test_rmse})\n\n# Define models to evaluate\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'SGD Regressor': SGDRegressor(),\n    'Random Forest': RandomForestRegressor(),\n    'ElasticNet': ElasticNet(),\n    'K-Neighbors Regressor': KNeighborsRegressor(),\n    'Decision Tree': DecisionTreeRegressor(),\n    'SVR': SVR(),\n    'XGBoost': XGBRegressor(),\n    'Gradient Boosting': GradientBoostingRegressor(),\n    'Bagging': BaggingRegressor()\n}\n\n# Iterate over the models to evaluate each\nfor model_name, model in models.items():\n    evaluate_model(model, X_train, y_train, X_test, y_test, model_name)\n\n# Convert results to a DataFrame\nresults_df = pd.DataFrame(results)\n\n# Plot R² comparison\nplt.figure(figsize=(10, 6))\nsns.barplot(x='R²', y='Model', data=results_df, palette=custom_palette)\nplt.title('Model Comparison (R² Score)')\nplt.show()\n\n# Plot RMSE comparison\nplt.figure(figsize=(10, 6))\nsns.barplot(x='RMSE', y='Model', data=results_df, palette=custom_palette)\nplt.title('Model Comparison (RMSE)')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-20T12:27:08.535030Z","iopub.status.idle":"2024-09-20T12:27:08.535729Z","shell.execute_reply.started":"2024-09-20T12:27:08.535365Z","shell.execute_reply":"2024-09-20T12:27:08.535399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"padding: 20px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); border: 3px solid #C33B2F; border-radius: 10px; width: 75%; margin: 20px auto; background-color: #f9f9f9;\">\n    <p style=\"font-size: 20px; font-family: Arial, sans-serif; line-height: 1.6em; color: #333; text-align: justify;\">\n        <strong>Wow!</strong> Just by removing one variable (Items Sold) the R² score dropped significantly from 99.8% to 54.3%! That’s a huge difference, but now we can be confident there’s no data leakage. While the results aren't as impressive, they are far more reliable.\n    </p>\n    <p style=\"font-size: 20px; font-family: Arial, sans-serif; line-height: 1.6em; color: #333; text-align: justify;\">\n        <strong>Let's try a few more things:</strong> \n        <ul style=\"font-size: 20px; font-family: Arial, sans-serif; color: #333; line-height: 1.6em; list-style-type: disc; margin-left: 20px;\">\n            <li>Use the Date column by extracting new features such as year, month, day, etc.</li>\n            <li>Drop Outliers.</li>\n            <li>Incorporate hyperparameter tuning for machine learning models to optimize performance.</li>\n            <li>Explore Deep Learning approaches to potentially improve results further.</li>\n        </ul>\n    </p>\n</div>\n","metadata":{}},{"cell_type":"code","source":"# remove outliers\nnumerical_cols = df.select_dtypes(include=['number']).columns\ndf = df[(np.abs(stats.zscore(df[numerical_cols])) < 3).all(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.538272Z","iopub.status.idle":"2024-09-20T12:27:08.538875Z","shell.execute_reply.started":"2024-09-20T12:27:08.538618Z","shell.execute_reply":"2024-09-20T12:27:08.538643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert Date to DateTime Format\ndf['Date'] = pd.to_datetime(df['Date'])\n\n# Set the Date Column as the Index\ndf.set_index('Date', inplace=True)\n\n# Extract useful date features\ndf['Year'] = df.index.year\ndf['Month'] = df.index.month\ndf['Day'] = df.index.day\ndf['DayOfWeek'] = df.index.dayofweek\ndf['IsWeekend'] = df['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.541322Z","iopub.status.idle":"2024-09-20T12:27:08.541889Z","shell.execute_reply.started":"2024-09-20T12:27:08.541638Z","shell.execute_reply":"2024-09-20T12:27:08.541663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define new features and target\nX = df[['Product ID', 'Discount Percentage', 'Marketing Spend (USD)', 'Store Location',\n       'Product Category', 'Holiday Effect', 'Year', 'Month', 'Day', 'DayOfWeek', 'IsWeekend']]\ny = df['Sales Revenue (USD)']\n\n# Split the data into training and testing sets (same as before)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Update lists of different datatypes\ncategorical_cols = ['Product ID', 'Store Location', 'Product Category']\nnumerical_cols = ['Discount Percentage', 'Marketing Spend (USD)', 'Year', 'Month', 'DayOfWeek']\nboolean_cols = ['Holiday Effect', 'IsWeekend']\n\n# Define preprocessing step (same as before)\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', MinMaxScaler(), numerical_cols),\n        ('bool', 'passthrough', boolean_cols),\n        ('cat', OneHotEncoder(), categorical_cols)\n    ])\n\n# Fit and transform the training data\nX_train_processed = preprocessor.fit_transform(X_train)\n\n# Transform the testing data\nX_test_processed = preprocessor.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.543834Z","iopub.status.idle":"2024-09-20T12:27:08.544353Z","shell.execute_reply.started":"2024-09-20T12:27:08.544119Z","shell.execute_reply":"2024-09-20T12:27:08.544142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize list to collect results\nresults = []\n\n# Define hyperparameter grids for the selected models\nparam_grids = {\n    'Decision Tree': {\n        'max_depth': [None, 10, 20],\n        'min_samples_split': [2, 5, 10],\n        'min_samples_leaf': [1, 2, 4]\n    },\n    'XGBoost': {\n        'n_estimators': [50, 100, 200],\n        'learning_rate': [0.01, 0.1, 0.3],\n        'max_depth': [3, 5, 7]\n    },\n    'Gradient Boosting': {\n        'n_estimators': [100, 200],\n        'learning_rate': [0.01, 0.1],\n        'max_depth': [3, 5]\n    }\n}\n\n# Function to evaluate models with hyperparameter tuning\ndef evaluate_model_with_tuning(model, param_grid, X_train, y_train, X_test, y_test, model_name):\n    if param_grid:\n        search = RandomizedSearchCV(model, param_grid, n_iter=10, cv=3, scoring='r2', random_state=42, n_jobs=-1)\n        search.fit(X_train, y_train)\n        best_model = search.best_estimator_\n        print(f\"Best params for {model_name}: {search.best_params_}\")\n    else:\n        best_model = model\n        best_model.fit(X_train, y_train)\n\n    # Make predictions on the test set\n    y_pred_test = best_model.predict(X_test)\n\n    # Calculate metrics: R² and RMSE\n    test_r2 = r2_score(y_test, y_pred_test)\n    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n\n    # Print results\n    print(f\"{model_name} Model:\")\n    print(f\"Test R²: {test_r2:.4f}\")\n    print(f\"Test RMSE: {test_rmse:.4f}\\n\")\n\n    # Append results to the list for visualization\n    results.append({'Model': model_name, 'R²': test_r2, 'RMSE': test_rmse})\n\n# Define models to evaluate\nmodels = {\n    'Decision Tree': DecisionTreeRegressor(),\n    'XGBoost': XGBRegressor(),\n    'Gradient Boosting': GradientBoostingRegressor()\n}\n\n# Iterate over the models to evaluate each with hyperparameter tuning\nfor model_name, model in models.items():\n    param_grid = param_grids.get(model_name, None)  # Get the param grid for the model, if available\n    evaluate_model_with_tuning(model, param_grid, X_train_processed, y_train, X_test_processed, y_test, model_name)\n\n# Convert results to a DataFrame\nresults_df = pd.DataFrame(results)\n\n# Plot R² comparison\nplt.figure(figsize=(10, 3))\nsns.barplot(x='R²', y='Model', data=results_df, palette=custom_palette)\nplt.title('Model Comparison (R² Score)')\nplt.show()\n\n# Plot RMSE comparison\nplt.figure(figsize=(10, 3))\nsns.barplot(x='RMSE', y='Model', data=results_df, palette=custom_palette)\nplt.title('Model Comparison (RMSE)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.546775Z","iopub.status.idle":"2024-09-20T12:27:08.547276Z","shell.execute_reply.started":"2024-09-20T12:27:08.547044Z","shell.execute_reply":"2024-09-20T12:27:08.547067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Neural Network wth TensorFlow\n\n# Define a Sequential model\nmodel = Sequential([\n    Dense(units=50, activation='relu'),\n    Dense(units=30, activation='relu'),\n    Dense(units=1, activation='relu')             # Output layer with ReLU activation (suitable for regression non-negative tasks)\n])\n\n# Compile the model with Mean Squared Error loss function and train the model\nmodel.compile(loss = MeanSquaredError())\nmodel.fit(X_train_processed, y_train, epochs=100)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.549129Z","iopub.status.idle":"2024-09-20T12:27:08.549599Z","shell.execute_reply.started":"2024-09-20T12:27:08.549373Z","shell.execute_reply":"2024-09-20T12:27:08.549395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test_processed)\n\ntest_r2 = r2_score(y_test, y_pred)\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    \nprint(f\"Test R²: {test_r2:.4f}\")\nprint(f\"Test RMSE: {test_rmse:.4f}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T12:27:08.551803Z","iopub.status.idle":"2024-09-20T12:27:08.552542Z","shell.execute_reply.started":"2024-09-20T12:27:08.552189Z","shell.execute_reply":"2024-09-20T12:27:08.552225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"padding: 20px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); border: 3px solid #C33B2F; border-radius: 10px; width: 75%; margin: 20px auto; background-color: #f9f9f9;\">\n    <p style=\"font-size: 20px; font-family: Arial, sans-serif; line-height: 1.6em; color: #333; text-align: justify;\">\n        <strong>Conclusion:</strong> </p>\n    <p style=\"font-size: 20px; font-family: Arial, sans-serif; line-height: 1.6em; color: #333; text-align: justify;\">\n        The best performing model in this analysis is the Gradient Boosting Model, with a Test R² of 0.5985 and a Test RMSE of 1419.7979. While these results may not seem exceptionally high, they are consistent with the findings from the exploratory data analysis (EDA), which revealed weak correlations between most features and the target variable. The exception was the number of items sold, which had a stronger correlation but was excluded from the model to avoid introducing data leakage.\n    </p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"padding: 25px; background-color: #F0F0F5; border-left: 6px solid #C33B2F; border-radius: 8px; max-width: 70%; margin: 40px auto; font-family: 'Verdana', sans-serif;\">\n    <p style=\"font-size: 26px; font-family: 'Arial'; line-height: 1.6em; color: #1560B0;\">\n        Thank you for your time and support! 🎉\n    </p>\n    <p style=\"font-size: 20px; font-family: 'Arial'; line-height: 1.5em; color: #C33B2F;\">\n        Your upvote and feedback is greatly appreciated and helps me improve. \n</div>\n\n","metadata":{}}]}